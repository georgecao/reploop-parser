// Author: Cangliang Li (licangliang@qiyi.com)
//
// Proto definitions for the hbase table schema.

package com.qiyi.hbase;

// Define column family configuration
message QiyiColumnFamily {
  // The column family name must be composed of printable characters(digit
  // or letter) and may not contain ':'.
  required string name = 1;

  // Additional remark for name.
  optional string description = 2;

  // Bloomfilter type.
  // HBase supports Bloom Filter to improve the overall throughput of the
  // cluster. A HBase Bloom Filter is a space-efficient mechanism to test
  // whether a StoreFile contains a specific row or row-col cell. Here are
  // the details of Bloom Filter http://en.wikipedia.org/wiki/Bloom_filter.
  // below status of bloom filters in Hbase:
  // Default = NONE for no bloom filters.
  // If ROW, the hash of the row will be added to the bloom on each insert.
  // If ROWCOL, the hash of the row + column family + column family qualifier
  // will be added to the bloom on each key insert
  enum BloomType {
    // Disable the filter(default)
    BFT_NONE = 1;

    // Use the row key for the filter
    ROW = 2;

    // Use the row key and column key (family+qualifier) for the filter
    ROWCOL = 3;
  }
  optional BloomType bloom_filter_type = 3 [default = BFT_NONE];

  // The maximum number of row versions to store is configured per column family.
  // The default for max versions is 3. HBase does not overwrite row values,
  // but rather stores different values per row by time (and qualifier). Excess
  // versions are removed during major compactions.
  // It is not recommended setting the number of max versions to an exceedingly
  // high level (e.g., hundreds or more) unless those old values are very dear
  // to you because this will greatly increase StoreFile size.
  optional int32 max_versions = 4 [default = 3];

  // The minimum number of versions to keep. (used when timeToLive is set)
  // The default for min versions is 0, which means the feature is disabled.
  // This parameter should only be set when time-to-live is enabled for a column
  // family and must be less than the number of row versions.
  optional int32 min_versions = 5;

  // Time-to-live of cell contents, in seconds (use HConstants.FOREVER for
  // unlimited TTL).
  optional int32 time_to_live = 6;

  // True if we are to keep all values of the column family in the HRegionServer
  // cache.
  optional bool in_memory = 7 [default = false];

  // Block size to use when writing out storefiles. Use smaller blocksizes for
  // faster random-access at expense of larger indices (more memory consumption).
  // Default is usually 64k.
  optional int32 block_size = 8 [default = 24576];

  // Compression types supported in hbase.
  // LZO is not bundled as part of the hbase distribution.
  enum CompressionAlgorithmType {
    // Gzip algorithm, it is deflate compressor. it is suitable for single
    // text file.
    GZ = 1;

    // LZ4 is a very fast lossless compressor, it provides better compression
    // ratio for text files and reaches impressive decompression speed, in the
    // range and beyond 1GB/s per core. especially for binary files. These
    // speeds are scalable with multi-threading modes, quickly reaching RAM
    // speed limits on multi-core systems.
    // hbase does not support it default.
    LZ4 = 2;

    // LZO is a block compression algorithm. it compresses and decompresses a
    // block of data. Block size must be the same for compression and
    // decompression. it can produce good results on highly redundant data
    // and deal acceptably with non-compressible data.
    LZO = 3;

    // Disable compression(default)
    CAT_NONE = 4;

    // SNAPPY is designed to be very fast and stable, but not to achieve a high
    // compression ratio.  Compression speed is 250 MB/s and decompression
    // speed is 500 MB/s using a single threaded, 64-bit Core i7 processor.
    // The compression ratio is 20~100% lower than gzip.
    // Snappy is widely used in Google projects like BigTable, MapReduce, and
    // in compression of RPC.
    SNAPPY = 5;
  }
  optional CompressionAlgorithmType compression_algorithm_type = 9 [default = CAT_NONE];

  // Compression type being used for the column family for major compression.
  optional CompressionAlgorithmType compression_algorithm_type_in_major_compaction = 10;

  // If true, MapFile blocks should be cached
  optional bool block_cache_enable = 11;

  // Data block is key-value set.
  // Data block encoding algorithm type used in block cache. Since keys are sorted and
  // and usually very similar, it can be better compressed. No encoding data below:
  //      KeyLen              Key
  //        24           Rowkey:family:qualifier0
  //        24           Rowkey:family:qualifier1
  //        24           Rowkey:family:qualifierN
  //        25           Rowkey1:family:qualifier1
  //        25           Rowkey1:family:qualifier2
  enum DataBlockEncoding {
    // Considering the key as an opaque sequence of bytes, the Diff Encoder
    // splits each key field in order to compress each part in a better way.
    // This being that the column family is stored once. If the key length,
    // value length and type are the same as the row prior, the field is omitted.
    // Also, for increased compression, the timestamp is stored is stored as a
    // Diff from the previous one. e.g:
    //  Flags KeyLen ValLen PrefixLen        Key                TimeStamp Type
    //   0     24     512     0       RowKey:family:qualifier0 1303232323  4
    //   5            320     23             1                    0
    //   3                    23             N                    120      8
    //   0     25     576     6         1:family:qualifier1       25       4
    //   5            384     24             2                    1222
    //
    // So it is suitable for keep many versions and have many same fields in rows.
    // And it has the best compression ratio, but CPU usage ratio is high.
    // [Recommend] as a general use.
    DIFF = 1;

    // Fast_DIFF works essentially the same way DIFF works, only VALUE content is
    // different. if row(key-value)'s value content are different with the nearest
    // above row(key-value), then stores, otherwise not stores.
    //
    // So it is suitable for many the same values.
    FAST_DIFF = 2;

    // Disable data block encoding
    DBE_NONE = 3;

    // The main idea of Prefix Encoding is to store the common prefix only once,
    // Since the rows are sorted and the beginning is typically the same. Only
    // stores the differences with above the nearest row. e.g:
    //      KeyLen        PrefixLen                Key
    //        24             0            RowKey:family:qualifier0
    //        1              23                    l
    //        1              23                    N
    //        19             6                     1:family:qualifier1
    //        1              24                    2
    //
    // So it is suitable for many the same rows.
    PREFIX = 4;

    // The main idea of Prefix-tree Encoding is to build three prefix-trees for row,
    // family, qualifier in keyvalue structure. e.g(row):
    //             row
    //            /
    //           1
    //
    // It is suitable for random get, one row multiple qualifier, reverse order
    // scan.
    PREFIX_TREE = 5;
  }
  optional DataBlockEncoding data_block_encoding = 12 [default = DBE_NONE];

  // Whether to retain deleted cells until they expire up to maxVersions versions.
  optional bool keep_deleted_cells = 13 [default = true];

  // Set the flag indicating that we only want to encode data block in cache
  // but not on disk.
  optional bool encode_on_disk = 14;

  // Cluster replication
  // value 0: local scope, i.e, no replication for this family
  // value 1: global scope, i.e, replicate family to a remote cluster.
  optional int32 scope = 15;
}

message QiyiTable {
  required string name = 1;

  // The maximum size upto which a region can grow to after which a region split
  // is triggered. If the biggest store file grows beyond the maxFileSize,
  // then the region split is triggered. This default is 256MB.
  // And this is not an absolute and might vary. Assume that a single row exceeds
  // this max_region_size then the region storeFileSize will be greater than
  // max_region_size since a single row cannot be split across multple regions.
  optional int64 max_region_size = 2;

  // Memory cache flush size for each hregion. The content of the memstore are
  // flushied to disk after up to the maximum size of the memstore. This default
  // is 64MB.
  optional int64 memstore_flush_size = 3;

  // True if deferred log edits are enabled on the table.
  // Note: deferring the log edit syncing to the disk, and this sync operation is
  // an expensive and thus can be deferred. So that the edits is kept in memory
  // for time as represented by hbase.regionserver.optionallogflushinterval and
  // not flushed for every edit.
  // WARN: this might result in data loss if the region server crashes before
  // these deferred edits in memory are flushed onto disk.
  // False if deferred log edits are disabled on the table.
  optional bool is_defer_log_flush = 4 [default = false];

  // True if all of the columns in the table is read only.
  // By default(false) all tables are modifiable.
  optional bool read_only = 5 [default = false];

  // Columns in Hbase are grouped into column family. All column members of a
  // column family have the same prefix. i.e, the column C:A and the column C:B
  // are both members of the C column family. The ':' delimits the column family.
  // Front the ':' C is column suffix, and behind the ':' A or B is qualifier.
  optional string default_delimiter = 6 [default = ":"];

  // Define Column family structure in the table. The column family name must be
  // composed of printable characters. Column families must be declared up front
  // at schema definition time. whereas columns do not need to be defined at
  // schema time.
  //
  // Note: HBase currently does not do well with anything above two or three column
  // families so keep the number of column families in your schema low. When many
  // column families the flushing and compaction interaction can make for a bunch
  // of needless i/o loading.
  // So try to make do with one column family in your schemas.
  //
  // Assume that ColumnFamilyA and ColumnFamilyB are in the same table, If
  // ColumnFamilyA has 1 million rows and ColumnFamilyB has 1 billion rows,
  // ColumnFamilyA's data will likely be spread across many, many regions (and
  // RegionServers). This makes mass scans for ColumnFamilyA less efficient.
  // So we must avoid this situation.
  repeated QiyiColumnFamily qiyi_column_family = 7;
}
